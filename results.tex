\section{Results}
\label{sec:results}

\subsection{Word boundary prediction}
Table x shows the precision scores for word boundary prediction and word onset detection. When looking at the models that take the activation patterns of the third hidden layer as input, precision is only marginally better than a default prediction of 'no word boundary', which would be correct in .72 of cases. % insert exact number 
However, when we look at the lower layers, precision is considerably better. [Comparison to performance of n-gram models here]
These results indicates that sub-word linguistic structure is mainly handled in the lower layers.

\begin{table}[]
	\centering
	\caption{Table x. Precision of word boundary prediction and detection}
	\begin{tabular}{lll}
		& Word ends      & Onsets         \\
		Layer 1 & 0.89   & 0.92 \\
		Layer 2 & 0.84  & 0.86 \\
		Layer 3 & 0.77 & 0.78
	\end{tabular}
\end{table}

\subsection{Word Similarity} % you may want to say semantic, although that is somewhat questionable, and relatedness rather than similarity...
Table y shows Spearmans rank correlation coefficient between human similarity ratings from the MEN dataset and the cosine similarity at the last timestep for all hidden layers. The results in the first column are based on the full dataset, and the second column only includes word pairs for which both words appeared at least 10 times in the training portion of MSCOCO. % make a choice already
The pattern in the cosine similarities at the different hidden layers shows that most semantic information is reflected in the activation pattern at the highest hidden layer, and somewhat less in the second hidden layer. However, even at layer 3 and for well-known words, Spearmans rank correlation coefficient is .31. Clearly, although the correlation is there, it is only weak.  % compare to some other results? How bad really is this? How come?
Unsurprisingly, the correlation is higher when only well-known words are included, at least for the second and third hidden layer. % ugly sentence


% report on lev and stuff... LOTS TO DO
% expected relation: when one of the words is frequent and the other is not, lev is predictive. if both are infrequent, it may be predictive too because they are both similar to a third word. However if both are frequent, lev is not as predictive. This is impossible to test on current data.

\begin{table}[]
	\centering
	\caption{Table y. Spearmans rank correlation between cosine similarity and human similarity judgements} % bad title
	\begin{tabular}{lll}
		& All words      & Frequent words only         \\
		Layer 1 & 0.07 & 0.07 \\
		Layer 2 & 0.21 & 0.23 \\
		Layer 3 & 0.28 & 0.31 
	\end{tabular}
\end{table}

% replacement results are on sentences from the training split. FIX
